{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naughty-appendix",
   "metadata": {},
   "source": [
    "<b> importing everything we need </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "sustained-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to install\n",
    "!spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-wings",
   "metadata": {},
   "source": [
    "<b> CONVERSION </b>\n",
    "\n",
    "<br>\n",
    "The main corpus folder consists of six folders which consist of .txt files of each song on that album. Below is the conversion of this folder to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "actual-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_files(folder_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                song_name = filename.replace('.txt', '')\n",
    "                lyrics = file.read()\n",
    "                data.append({\"Album\": os.path.basename(folder_path), \"Song Name\": song_name, \"Lyrics\": lyrics})\n",
    "    return data\n",
    "\n",
    "def convert_to_csv(input_folders, output_csv):\n",
    "    all_data = []\n",
    "    for folder in input_folders:\n",
    "        folder_data = read_text_files(folder)\n",
    "        all_data.extend(folder_data)\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = [\"Album\", \"Song Name\", \"Lyrics\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in all_data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "input_folders = [\n",
    "    \"texts\\\\Suicide Season\",\n",
    "    \"texts\\\\There Is A Hell\",\n",
    "    \"texts\\\\Sempiternal\",\n",
    "    \"texts\\\\That's The Spirit\",\n",
    "    \"texts\\\\Amo\",\n",
    "    \"texts\\\\Post Human\"\n",
    "]\n",
    "output_csv = \"BMTH_Discography.csv\"\n",
    "\n",
    "convert_to_csv(input_folders, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "average-routine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Cleaned Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>Chelsea Smile</td>\n",
       "      <td>I've got a secret.\\nIt's on the tip of my tong...</td>\n",
       "      <td>i've got a secret. it's on the tip of my tongu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>Death Breath</td>\n",
       "      <td>The sun goes down, we come out, a different pa...</td>\n",
       "      <td>the sun goes down, we come out, a different pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>Diamonds Aren't Forever</td>\n",
       "      <td>We will never sleep 'cause sleep is for the we...</td>\n",
       "      <td>we will never sleep 'cause sleep is for the we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>Football Season Is Over</td>\n",
       "      <td>Why the fuck can I not hail a taxi?\\nArm out l...</td>\n",
       "      <td>why the fuck can i not hail a taxi? arm out li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>It Was Written in Blood</td>\n",
       "      <td>Goodbye, my friend, goodbye, my love, you're i...</td>\n",
       "      <td>goodbye, my friend, goodbye, my love, you're i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Album                Song Name  \\\n",
       "0  Suicide Season            Chelsea Smile   \n",
       "1  Suicide Season             Death Breath   \n",
       "2  Suicide Season  Diamonds Aren't Forever   \n",
       "3  Suicide Season  Football Season Is Over   \n",
       "4  Suicide Season  It Was Written in Blood   \n",
       "\n",
       "                                              Lyrics  \\\n",
       "0  I've got a secret.\\nIt's on the tip of my tong...   \n",
       "1  The sun goes down, we come out, a different pa...   \n",
       "2  We will never sleep 'cause sleep is for the we...   \n",
       "3  Why the fuck can I not hail a taxi?\\nArm out l...   \n",
       "4  Goodbye, my friend, goodbye, my love, you're i...   \n",
       "\n",
       "                                      Cleaned Lyrics  \n",
       "0  i've got a secret. it's on the tip of my tongu...  \n",
       "1  the sun goes down, we come out, a different pa...  \n",
       "2  we will never sleep 'cause sleep is for the we...  \n",
       "3  why the fuck can i not hail a taxi? arm out li...  \n",
       "4  goodbye, my friend, goodbye, my love, you're i...  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"BMTH_Discography.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "df['Cleaned Lyrics'] = df['Lyrics'].str.replace('\\s+', ' ', regex=True).str.strip()\n",
    "df['Cleaned Lyrics'] = df['Cleaned Lyrics'].str.lower()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-bidder",
   "metadata": {},
   "source": [
    "<b> SPACY ANNOTATION </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "adapted-greene",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_trf')\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-continuity",
   "metadata": {},
   "source": [
    "This first uses spaCy to process the text, creating a token called 'Doc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "preceding-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    return nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "raising-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Doc'] = df['Cleaned Lyrics'].apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-thanks",
   "metadata": {},
   "source": [
    "This step tokenizes the processed text, creating a Tokenized version of the lyrics of every song in the CSV and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "chief-siemens",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_token(doc):\n",
    "    return [(token.text) for token in doc]\n",
    "df['Tokens'] = df['Doc'].apply(get_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "individual-worship",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned Lyrics</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i've got a secret. it's on the tip of my tongu...</td>\n",
       "      <td>[i, 've, got, a, secret, ., it, 's, on, the, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the sun goes down, we come out, a different pa...</td>\n",
       "      <td>[the, sun, goes, down, ,, we, come, out, ,, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we will never sleep 'cause sleep is for the we...</td>\n",
       "      <td>[we, will, never, sleep, 'cause, sleep, is, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why the fuck can i not hail a taxi? arm out li...</td>\n",
       "      <td>[why, the, fuck, can, i, not, hail, a, taxi, ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goodbye, my friend, goodbye, my love, you're i...</td>\n",
       "      <td>[goodbye, ,, my, friend, ,, goodbye, ,, my, lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Cleaned Lyrics  \\\n",
       "0  i've got a secret. it's on the tip of my tongu...   \n",
       "1  the sun goes down, we come out, a different pa...   \n",
       "2  we will never sleep 'cause sleep is for the we...   \n",
       "3  why the fuck can i not hail a taxi? arm out li...   \n",
       "4  goodbye, my friend, goodbye, my love, you're i...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [i, 've, got, a, secret, ., it, 's, on, the, t...  \n",
       "1  [the, sun, goes, down, ,, we, come, out, ,, a,...  \n",
       "2  [we, will, never, sleep, 'cause, sleep, is, fo...  \n",
       "3  [why, the, fuck, can, i, not, hail, a, taxi, ?...  \n",
       "4  [goodbye, ,, my, friend, ,, goodbye, ,, my, lo...  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = df[['Cleaned Lyrics', 'Tokens']].copy()\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-mailing",
   "metadata": {},
   "source": [
    "The following steps creates use the processed text in the 'Doc' column to create columns consisting of the Lemma's, Part-of-Speech, Named Entities and the words of Named Entities of the original processed text, every row being a BMTH song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "secret-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(doc):\n",
    "    return [(token.lemma_) for token in doc]\n",
    "\n",
    "df['Lemmas'] = df['Doc'].apply(get_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "precise-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(doc):\n",
    "    return [(token.pos_, token.tag_) for token in doc]\n",
    "\n",
    "df['POS'] = df['Doc'].apply(get_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "prompt-hotel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_named_entities(doc):\n",
    "    return [ent.label_ for ent in doc.ents]\n",
    "\n",
    "df['Named_Entities'] = df['Doc'].apply(extract_named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "private-suite",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_ne_words(doc):\n",
    "    return [ent for ent in doc.ents]\n",
    "\n",
    "df['NE_Words'] = df['Doc'].apply(extract_ne_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-italic",
   "metadata": {},
   "source": [
    "The last step shows the final result of the DataFrame, and saving it to a new CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "improved-theology",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Cleaned Lyrics</th>\n",
       "      <th>Doc</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>POS</th>\n",
       "      <th>Named_Entities</th>\n",
       "      <th>NE_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>Chelsea Smile</td>\n",
       "      <td>I've got a secret.\\nIt's on the tip of my tong...</td>\n",
       "      <td>i've got a secret. it's on the tip of my tongu...</td>\n",
       "      <td>(i, 've, got, a, secret, ., it, 's, on, the, t...</td>\n",
       "      <td>[i, 've, got, a, secret, ., it, 's, on, the, t...</td>\n",
       "      <td>[I, have, get, a, secret, ., it, be, on, the, ...</td>\n",
       "      <td>[(PRON, PRP), (AUX, VBP), (VERB, VBD), (DET, D...</td>\n",
       "      <td>[TIME, TIME]</td>\n",
       "      <td>[(night), (night)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>Death Breath</td>\n",
       "      <td>The sun goes down, we come out, a different pa...</td>\n",
       "      <td>the sun goes down, we come out, a different pa...</td>\n",
       "      <td>(the, sun, goes, down, ,, we, come, out, ,, a,...</td>\n",
       "      <td>[the, sun, goes, down, ,, we, come, out, ,, a,...</td>\n",
       "      <td>[the, sun, go, down, ,, we, come, out, ,, a, d...</td>\n",
       "      <td>[(DET, DT), (NOUN, NN), (VERB, VBZ), (ADP, RP)...</td>\n",
       "      <td>[TIME, DATE, TIME, TIME, DATE]</td>\n",
       "      <td>[(this, fucking, night), (days), (this, fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>Diamonds Aren't Forever</td>\n",
       "      <td>We will never sleep 'cause sleep is for the we...</td>\n",
       "      <td>we will never sleep 'cause sleep is for the we...</td>\n",
       "      <td>(we, will, never, sleep, 'cause, sleep, is, fo...</td>\n",
       "      <td>[we, will, never, sleep, 'cause, sleep, is, fo...</td>\n",
       "      <td>[we, will, never, sleep, 'cause, sleep, be, fo...</td>\n",
       "      <td>[(PRON, PRP), (AUX, MD), (ADV, RB), (VERB, VB)...</td>\n",
       "      <td>[CARDINAL]</td>\n",
       "      <td>[(one)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>Football Season Is Over</td>\n",
       "      <td>Why the fuck can I not hail a taxi?\\nArm out l...</td>\n",
       "      <td>why the fuck can i not hail a taxi? arm out li...</td>\n",
       "      <td>(why, the, fuck, can, i, not, hail, a, taxi, ?...</td>\n",
       "      <td>[why, the, fuck, can, i, not, hail, a, taxi, ?...</td>\n",
       "      <td>[why, the, fuck, can, I, not, hail, a, taxi, ?...</td>\n",
       "      <td>[(SCONJ, WRB), (DET, DT), (NOUN, NN), (AUX, MD...</td>\n",
       "      <td>[NORP, DATE, DATE, CARDINAL, TIME, TIME, TIME,...</td>\n",
       "      <td>[(nazi), (today), (today), (one), (last, night...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suicide Season</td>\n",
       "      <td>It Was Written in Blood</td>\n",
       "      <td>Goodbye, my friend, goodbye, my love, you're i...</td>\n",
       "      <td>goodbye, my friend, goodbye, my love, you're i...</td>\n",
       "      <td>(goodbye, ,, my, friend, ,, goodbye, ,, my, lo...</td>\n",
       "      <td>[goodbye, ,, my, friend, ,, goodbye, ,, my, lo...</td>\n",
       "      <td>[goodbye, ,, my, friend, ,, goodbye, ,, my, lo...</td>\n",
       "      <td>[(INTJ, UH), (PUNCT, ,), (PRON, PRP$), (NOUN, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Album                Song Name  \\\n",
       "0  Suicide Season            Chelsea Smile   \n",
       "1  Suicide Season             Death Breath   \n",
       "2  Suicide Season  Diamonds Aren't Forever   \n",
       "3  Suicide Season  Football Season Is Over   \n",
       "4  Suicide Season  It Was Written in Blood   \n",
       "\n",
       "                                              Lyrics  \\\n",
       "0  I've got a secret.\\nIt's on the tip of my tong...   \n",
       "1  The sun goes down, we come out, a different pa...   \n",
       "2  We will never sleep 'cause sleep is for the we...   \n",
       "3  Why the fuck can I not hail a taxi?\\nArm out l...   \n",
       "4  Goodbye, my friend, goodbye, my love, you're i...   \n",
       "\n",
       "                                      Cleaned Lyrics  \\\n",
       "0  i've got a secret. it's on the tip of my tongu...   \n",
       "1  the sun goes down, we come out, a different pa...   \n",
       "2  we will never sleep 'cause sleep is for the we...   \n",
       "3  why the fuck can i not hail a taxi? arm out li...   \n",
       "4  goodbye, my friend, goodbye, my love, you're i...   \n",
       "\n",
       "                                                 Doc  \\\n",
       "0  (i, 've, got, a, secret, ., it, 's, on, the, t...   \n",
       "1  (the, sun, goes, down, ,, we, come, out, ,, a,...   \n",
       "2  (we, will, never, sleep, 'cause, sleep, is, fo...   \n",
       "3  (why, the, fuck, can, i, not, hail, a, taxi, ?...   \n",
       "4  (goodbye, ,, my, friend, ,, goodbye, ,, my, lo...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [i, 've, got, a, secret, ., it, 's, on, the, t...   \n",
       "1  [the, sun, goes, down, ,, we, come, out, ,, a,...   \n",
       "2  [we, will, never, sleep, 'cause, sleep, is, fo...   \n",
       "3  [why, the, fuck, can, i, not, hail, a, taxi, ?...   \n",
       "4  [goodbye, ,, my, friend, ,, goodbye, ,, my, lo...   \n",
       "\n",
       "                                              Lemmas  \\\n",
       "0  [I, have, get, a, secret, ., it, be, on, the, ...   \n",
       "1  [the, sun, go, down, ,, we, come, out, ,, a, d...   \n",
       "2  [we, will, never, sleep, 'cause, sleep, be, fo...   \n",
       "3  [why, the, fuck, can, I, not, hail, a, taxi, ?...   \n",
       "4  [goodbye, ,, my, friend, ,, goodbye, ,, my, lo...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [(PRON, PRP), (AUX, VBP), (VERB, VBD), (DET, D...   \n",
       "1  [(DET, DT), (NOUN, NN), (VERB, VBZ), (ADP, RP)...   \n",
       "2  [(PRON, PRP), (AUX, MD), (ADV, RB), (VERB, VB)...   \n",
       "3  [(SCONJ, WRB), (DET, DT), (NOUN, NN), (AUX, MD...   \n",
       "4  [(INTJ, UH), (PUNCT, ,), (PRON, PRP$), (NOUN, ...   \n",
       "\n",
       "                                      Named_Entities  \\\n",
       "0                                       [TIME, TIME]   \n",
       "1                     [TIME, DATE, TIME, TIME, DATE]   \n",
       "2                                         [CARDINAL]   \n",
       "3  [NORP, DATE, DATE, CARDINAL, TIME, TIME, TIME,...   \n",
       "4                                                 []   \n",
       "\n",
       "                                            NE_Words  \n",
       "0                                 [(night), (night)]  \n",
       "1  [(this, fucking, night), (days), (this, fuckin...  \n",
       "2                                            [(one)]  \n",
       "3  [(nazi), (today), (today), (one), (last, night...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "municipal-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BMTH_Discography_annotation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-strap",
   "metadata": {},
   "source": [
    "<b> BONUS: for fun </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-consciousness",
   "metadata": {},
   "source": [
    "<b> AVERAGE WORDS PER ALBUM </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-organ",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Total_Words_Per_Song'] = df['Cleaned Lyrics'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "average_total_words_per_song = df.groupby('Album')['Total_Words_Per_Song'].mean().reset_index()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Album', y='Total_Words_Per_Song', data=average_total_words_per_song)\n",
    "plt.title('Average Total Words Per Song Across Albums')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-civilization",
   "metadata": {},
   "source": [
    "<b> SENTIMENT ANALYSIS </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Cleaned Lyrics'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sentiment_per_album = df.groupby('Album')['Sentiment'].mean().reset_index()\n",
    "sns.barplot(x='Album', y='Sentiment', data=avg_sentiment_per_album)\n",
    "plt.title('Average Sentiment Score per Album')\n",
    "plt.xlabel('Album')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
